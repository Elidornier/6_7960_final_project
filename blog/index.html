<!DOCTYPE html>
<html>
<head>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
<link rel="shortcut icon" href="images/icon.ico">
<style type="text/css">
    /* 1. BASIC PAGE SETUP */
    body {
        background-color: #ffffff; /* Clean white background */
        color: #333333; /* Dark gray text is easier on eyes than pitch black */
        font-family: "Georgia", "Times New Roman", serif; /* Serif font for the main reading */
        font-size: 20px; /* Distill uses large, readable text */
        line-height: 1.6em; /* More breathing room between lines */
        margin: 0;
    }

    /* 2. LINKS (Blue) */
    a:link, a:visited {
        color: #2e6db2; 
        text-decoration: none;
        border-bottom: 1px solid #e0e0e0; /* Subtle underline */
    }
    a:hover {
        color: #1a4e85;
        border-bottom: 2px solid #1a4e85;
    }

    /* 3. LAYOUT GRID */
    .content-margin-container {
        display: flex;
        width: 100%;
        justify-content: center;
        align-items: flex-start; /* Aligns content to top */
        margin-bottom: 20px;
    }

    /* 4. MAIN COLUMN (Narrower for readability) */
    .main-content-block {
        width: 55%; 
        max-width: 720px; /* Optimal reading width */
        background-color: #fff;
        padding: 0px;
        /* We REMOVED the borders here */
        border: none; 
    }

    /* 5. MARGIN NOTES */
    .margin-left-block {
        width: 20%;
        max-width: 180px;
        margin-right: 30px;
        text-align: right;
        font-size: 14px;
        color: #6b6b6b;
        font-family: "HelveticaNeue-Light", "Helvetica Neue", sans-serif; /* Sidenotes stay sans-serif */
        line-height: 1.4em;
    }

    .margin-right-block {
        width: 20%;
        max-width: 220px; /* Slightly wider right margin */
        margin-left: 30px;
        text-align: left;
        font-size: 13px;
        color: #6b6b6b;
        font-family: "HelveticaNeue-Light", "Helvetica Neue", sans-serif;
        line-height: 1.4em;
    }

    /* 6. HEADERS */
    h1, h2, h3 {
        font-family: "HelveticaNeue-Light", "Helvetica Neue", Helvetica, Arial, sans-serif;
        color: #000;
        margin-top: 50px;
        margin-bottom: 15px;
        font-weight: 600;
        line-height: 1.2em;
    }
    h1 { font-size: 36px; letter-spacing: -0.5px; } /* Big section headers */
    h2 { font-size: 26px; border-bottom: 1px solid #eee; padding-bottom: 10px; }
    h3 { font-size: 20px; font-weight: 600; margin-top: 30px;}

    /* 7. IMAGES & CAPTIONS */
    img, .my-video {
        max-width: 100%;
        height: auto;
        display: block;
        margin: 20px auto;
        border-radius: 4px; 
        box-shadow: 0 4px 10px rgba(0,0,0,0.05); /* Subtle shadow for images */
    }

    /* 8. MATH & CODE */
    .mathjax-mobile, .mathml-non-mobile { display: none; }
    .show-mathml .mathml-non-mobile { display: block; }
    .show-mathjax .mathjax-mobile { display: block; }
    
    code {
        background-color: #f4f4f4;
        padding: 2px 5px;
        border-radius: 3px;
        font-family: "Courier New", Courier, monospace;
        font-size: 0.9em;
    }

    /* 9. CITATION BLOCK */
    div.citation {
        font-family: "HelveticaNeue-Light", "Helvetica Neue", sans-serif;
        font-size: 14px;
        background-color: #f7f7f7;
        padding: 20px;
        border-radius: 5px;
        border: 1px solid #eee;
    }

    /* 10. TITLE HEADER TABLE SPECIFIC */
    table.header {
        width: 100%;
        max-width: 100%;
    }

    /* 11. TOP NAVIGATION BAR */
    .nav-header {
        background-color: #23374d; /* Navy Blue */
        width: 100%;
        display: flex;
        justify-content: center;
        padding: 15px 0;
        font-family: "HelveticaNeue-Light", "Helvetica Neue", Helvetica, Arial, sans-serif;
        border-bottom: 1px solid rgba(0,0,0,0.1);
    }
    
    .nav-inner {
        width: 90%; 
        max-width: 1080px; /* Matches the width of the article content */
        display: flex;
        justify-content: space-between;
        align-items: center;
    }

    .nav-logo {
        font-weight: 600;
        font-size: 18px;
        color: white !important; /* Force white text */
        border-bottom: none !important; /* Remove underline */
        display: flex;
        align-items: center;
    }

    .nav-links a {
        color: rgba(255,255,255,0.7) !important; /* Slightly transparent white */
        margin-left: 25px;
        font-size: 12px;
        font-weight: 500;
        text-transform: uppercase; /* MAKES TEXT CAPS */
        letter-spacing: 0.5px;
        border-bottom: none !important;
        transition: color 0.2s;
    }

    .nav-links a:hover {
        color: #ffffff !important; /* Bright white on hover */
    }

</style>

<title>Trajectory of Augmentation Difficulty</title>
<meta property="og:title" content="Trajectory of Augmentation Difficulty" />
<meta charset="UTF-8">
</head>

<body>

<div class="nav-header">
    <div class="nav-inner">
        <a href="#" class="nav-logo">
            <span class="logo-icon"></span> 6.7960 Project
        </a>
        
        <div class="nav-links">
            <a href="#">About</a>
            <a href="#">Paper</a>
            <a href="#">Code</a>
            <a href="#">Team</a>
        </div>
    </div>
</div>

<div class="content-margin-container" style="margin-top: 60px; margin-bottom: 60px;">
    <div class="margin-left-block"></div>
    <div class="main-content-block">
        <h1 style="font-size: 50px; line-height: 1.1em; margin-bottom: 20px; font-family: 'Helvetica Neue', Helvetica, sans-serif;">
            Investigating the Trajectory<br>of Augmentation Difficulty
        </h1>
        
        <div style="font-family: 'Helvetica Neue', sans-serif; font-size: 18px; color: #555;">
            <p>
                <a href="#">Alice Xiao</a>, 
                <a href="#">Aimee Yu</a>, 
                <a href="#">Celinda Zhu</a>
            </p>
            <p style="font-size: 15px; color: #888;">
                Final Project for 6.7960, MIT &bull; Fall 2025
            </p>
        </div>
    </div>
    <div class="margin-right-block"></div>
</div>


<div class="content-margin-container" id="intro">
    <div class="margin-left-block">
        <div style="position:fixed; max-width:inherit; top:max(20%,120px)">
            <b style="font-size:16px">Outline</b><br><br>
            <a href="#intro">Introduction</a><br><br>
            <a href="#related_work">Related Work</a><br><br>
            <a href="#methodology">Methodology</a><br><br>
            <a href="#experiments">Experiments & Results</a><br><br>
            <a href="#discussion">Discussion</a><br><br>
        </div>
    </div>
    <div class="main-content-block">
        <h1>1. Introduction</h1>
        
        <h3>Motivation</h3>
        <p>
            Deep learning's remarkable success in computer vision can be attributed in large part to the capacity of powerful, over-parameterized models such as ResNet <a href="#ref_1">[1]</a> to generalize effectively beyond their training data. Consequently, Data Augmentation has emerged as a cornerstone technique to bridge the generalization gap, artificially expanding the training distribution through stochastic transformations like blurring, cropping, and occlusion.
        </p>
        <p>
            In our previous homework, we explored the critical role of data augmentation in enhancing model performance and shaping representation with implemented transformations such as <code>RandomHorizontalFlip</code> and <code>RandomCrop</code> on the CIFAR-10 dataset. Through this, we observed that while augmentation made fitting the training data more challenging, it could effectively reduce overfitting and improve validation and test accuracy, demonstrating better generalization. Motivated by these findings on how data manipulation fundamentally alters the decision boundaries and distinct properties of learned features, we decided to dig deeper into this topic.
        </p>
        <p>
            However, standard data augmentation pipelines typically treat the training process as static. Augmentations are applied with random magnitudes drawn from a fixed distribution, regardless of the model's current learning state. This creates a fundamental misalignment between the data and the model:
        </p>
        <ul style="margin-left: 20px; line-height: 1.6em;">
            <li style="margin-bottom: 10px;">
                In <strong>early training stages</strong>, the model is trying to learn basic, low-level features like edges or shapes. Strong augmentations (such as massive cutout holes or high-frequency noise) might introduce excessive information loss, essentially "blinding" the model before it can see.
            </li>
            <li>
                In <strong>later training stages</strong>, the model has likely memorized the training data. Weak augmentations may fail to provide sufficient regularization, leading to overfitting.
            </li>
        </ul>
        <p>
            We hypothesize that the trajectory of difficulty is just as critical as the difficulty itself. Just as a human student would struggle if handed a complex calculus problem on day one, a neural network might struggle to converge if the signal-to-noise ratio is too low at initialization.
        </p>

        <h3>Curriculum Learning</h3>
        <p>
            Curriculum Learning, as proposed by Bengio et al. <a href="#ref_3">[3]</a>, formalizes this intuition. It suggests that models learn more effectively when samples are presented in a meaningful order of increasing difficulty ("Easy-to-Hard"). Recent adaptive frameworks like EntAugment <a href="#ref_5">[5]</a> and ObjBlur <a href="#ref_4">[4]</a> have successfully applied this principle to data augmentation.
        </p>
        <p>
            Conversely, a counter-intuitive line of research suggests an "Anti-Curriculum" (Hard-to-Easy) approach. Theoretical work by Maltser <a href="#ref_6">[6]</a> indicates that exposing models to difficult, strongly augmented samples early on might force the learning of more robust, shape-invariant features. By front-loading the difficulty, the model may be prevented from learning "shortcuts" (like superficial texture bias) during its initial phase of high plasticity.
        </p>

        <h3>Our Contribution</h3>
        <p>
            In this work, we systematically investigate the <strong>trajectory of difficulty</strong> in data augmentation. We do not merely ask <em>if</em> curriculum learning helps; we ask <em>which trajectory</em> is optimal. We define our core question: <em>Should augmentation difficulty increase or decrease over training, and does the direction of this curriculum significantly affect generalization on CIFAR-10/100?</em>
        </p>
        
        <p>We explore two distinct axes of difficulty:</p>
        <ol style="margin-left: 20px; line-height: 1.6em;">
            <li style="margin-bottom: 10px;">
                <strong>Complexity-based:</strong> Using Colorful Cutout <a href="#ref_7">[7]</a> to vary the information entropy of the occluded region.
            </li>
            <li>
                <strong>Occlusion-based:</strong> Using Dynamic Cutout Size, a method we implemented to vary the spatial extent of information loss.
            </li>
        </ol>

        <p>and compare three distinct training regimes:</p>
        <ol style="margin-left: 20px; line-height: 1.6em;">
            <li style="margin-bottom: 10px;">
                <strong>Static Baseline:</strong> Random augmentation magnitude (Standard practice).
            </li>
            <li style="margin-bottom: 10px;">
                <strong>Curriculum (Easy &rarr; Hard):</strong> Gradually increasing complexity/occlusion.
            </li>
            <li>
                <strong>Anti-Curriculum (Hard &rarr; Easy):</strong> Gradually decreasing complexity/occlusion.
            </li>
        </ol>

        <p>
            By training ResNet50 architectures on CIFAR-10 and CIFAR-100 under these varying dynamics, we aim to decouple the impact of augmentation type from augmentation scheduling.
        </p>
        <img src="./images/your_intro_diagram.png" width=512px/>
    </div>
    <div class="margin-right-block">
        <div style="margin-bottom: 20px;">
            <strong>Hypothesis:</strong><br>
            Does early exposure to "hard" augmentations (Anti-Curriculum) induce better robustness than the traditional "Easy-to-Hard" Curriculum?
        </div>
    </div>
</div>

<div class="content-margin-container" id="related_work">
    <div class="margin-left-block"></div>
    <div class="main-content-block">
        <h1>2. Related Work</h1>
        <p>
            Recent research has pivoted toward <strong>adaptive</strong> strategies that integrate curriculum learning: models learn faster and better when training examples are ordered from easy to hard <a href="#ref_3">[3]</a>.
        </p>
        <ul>
            <li><strong>ObjBlur <a href="#ref_4">[4]</a>:</strong> Introduces a curriculum for layout-to-image generation by progressively moving from strong blurring (low-frequency signals) to cleaner images (high-frequency details).</li>
            <li><strong>EntAugment <a href="#ref_5">[5]</a>:</strong> Proposes a tuning-free framework that adapts augmentation magnitude based on sample difficulty. It utilizes an entropy-based metric to assess model confidence, applying lighter augmentations to hard samples early in training and intensifying the magnitude as the model generalizes.</li>
        </ul>

        <h3>Magnitude-Based Scheduling</h3>
        <p>
            A key subset of Curriculum Data Augmentation focuses specifically on scheduling the <strong>intensity</strong> or <strong>magnitude</strong> of transformations. Wei et al. (2020) demonstrated that gradually increasing the magnitude of distortions (e.g., rotation angle, shear intensity) correlates with improved generalization <a href="#ref_9">[9]</a>.
        </p>
        <p>
            In the context of occlusion methods, this magnitude corresponds directly to the <strong>size</strong> of the erased region. While early occlusion methods like Cutout <a href="#ref_2">[2]</a> and Random Erasing utilized fixed or randomly sampled sizes, later works such as Hide-and-Seek highlighted the delicate balance required between occlusion and feature retention. Our <strong>Dynamic Cutout Size</strong> implementation serves as a direct instantiation of magnitude-based curriculum for occlusion: we explicitly schedule the bounding box dimension ($W \times H$) as a function of the training epoch.
        </p>

        <h3>The Directionality Debate</h3>
        <p>
            Finally, a critical, yet under-explored question is the <strong>trajectory</strong> of augmentation difficulty. While standard CL dictates an "Easy-to-Hard" schedule, recent work by Maltser on <strong>Augmentation Curriculum Learning (ACL)</strong> investigates alternative pacing, including "Anti-Curriculum" (Hard-to-Easy) strategies <a href="#ref_6">[6]</a>. Maltser's findings suggest that explicitly scoring and ordering augmentations can outperform random selection, but the optimal direction remains a subject of debate.
        </p>
        <p>
            In this project, we utilize <strong>Colorful Cutout</strong> <a href="#ref_7">[7]</a> to test these conflicting hypotheses. By progressively dividing the erasure box into smaller sub-regions, Colorful Cutout allows us to control the "complexity" of the noise. As the number of sub-regions increases, the sample becomes more "tangled" and difficult, naturally forming a difficulty gradient that we can invert or scale.
        </p>
    </div>
    <div class="margin-right-block">
        <strong>Key Concept:</strong><br>
        <em>Magnitude Scheduling</em>: Varying the intensity (size) of an augmentation over time.
    </div>
</div>

<div class="content-margin-container" id="methodology">
    <div class="margin-left-block"></div>
    <div class="main-content-block">
        <h1>3. Methodology</h1>
        
        <h3>3.1 Setup</h3>
        <p>
            To isolate the effect of the curriculum, we needed a rigorously controlled environment. We didn't want model capacity or hyperparameter tuning to affect the result, so we kept the training recipe the same across augmentations.
        </p>
        <ul style="margin-left: 20px; line-height: 1.6em;">
            <li style="margin-bottom: 10px;"><strong>Task:</strong> Supervised image classification.</li>
            <li style="margin-bottom: 10px;"><strong>Datasets:</strong> We evaluated performance on CIFAR-10 and CIFAR-100. CIFAR images (32×32) are resized to 256×256 then cropped to 244×244 and normalized for ResNet-50. We tested two distinct data availability regimes:
                <ul style="margin-top: 5px; margin-bottom: 5px; list-style-type: circle;">
                    <li><strong>Full Data:</strong> We use the entire training split after the train/validation partition.</li>
                    <li><strong>Low-Data (10%):</strong> We subsample the training split to retain only a fixed fraction <i>f=0.1</i>.</li>
                </ul>
            </li>
            <li><strong>Model:</strong> ResNet-50.</li>
            <li><strong>Metric:</strong> Classification accuracy.</li>
        </ul>
        
        <p>
            Given an input image <i style="font-family: serif;">x</i> &in; &#8477;<sup>3 &times; H &times; W</sup>, the backbone produces a feature tensor which we globally pool and flatten into a vector <i style="font-family: serif;">h</i> &in; &#8477;<sup>d</sup>. The final prediction layer is a small MLP classifier. We train the model to minimize cross-entropy loss with label smoothing to mitigate overconfidence.
        </p>

        <h3>3.2 Augmentations</h3>
        <p>
            We investigated two types of augmentation. Each has a difficulty level we can change during training.
        </p>

        <ul style="list-style-type: disc; margin-left: 20px;">
            
            <li style="margin-bottom: 25px;">
                <strong>A. Colorful Cutout (Complexity-based Difficulty)</strong>
                <div style="margin-top: 5px; margin-bottom: 10px;">
                    This augmentation is implemented based on the Colorful Cutout; this places a single box of random noise over the image.
                </div>
                <ul style="list-style-type: circle; margin-left: 20px;">
                    <li style="margin-bottom: 8px;">
                        <strong>Mechanism:</strong> For a bounding box of size <i style="font-family: serif;">B</i>, we define a <code>region_size</code> <i style="font-family: serif;">S</i>. The box is divided into (<i style="font-family: serif;">B/S</i>)<sup>2</sup> sub-squares. Each sub-square is filled with a random color.
                    </li>
                    <li style="margin-bottom: 8px;">
                        <strong>Difficulty Metric:</strong> As <i style="font-family: serif;">S</i> decreases, the number of sub-regions increases, creating higher-frequency color noise (higher entropy).
                    </li>
                    <li style="margin-bottom: 8px;">
                        <strong>Code Implementation:</strong>
                        <div style="margin: 10px 0; text-align: left; padding-left: 20px;">
                             <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
                              <mi>S</mi>
                              <mo>=</mo>
                              <mfrac>
                                <mi>B</mi>
                                <msup>
                                  <mn>2</mn>
                                  <mtext>exponent</mtext>
                                </msup>
                              </mfrac>
                            </math>
                        </div>
                        Where <code>exponent</code> is the curriculum variable controlled by the epoch index.
                    </li>
                </ul>
            </li>
            <img src="./images/color_incr.png" width=700px/>
            <img src="./images/color_decr.png" width=700px/>
            <li style="margin-bottom: 25px;">
                <strong>B. Dynamic Cutout Size (Occlusion-based Difficulty)</strong>
                <div style="margin-top: 5px; margin-bottom: 10px;">
                    This method varies the spatial extent of the occlusion. We dynamically calculate the side length of the square mask, <i style="font-family: serif;">L<sub>mask</sub></i>, based on the current epoch.
                </div>
                <ul style="list-style-type: circle; margin-left: 20px;">
                    <li style="margin-bottom: 8px;">
                        <strong>Mechanism:</strong> We linearly interpolate the mask size between a minimum (<i style="font-family: serif;">L<sub>min</sub></i>) and maximum (<i style="font-family: serif;">L<sub>max</sub></i>) value.
                    </li>
                    <li style="margin-bottom: 8px;">
                        <strong>Difficulty Metric:</strong> Larger <i style="font-family: serif;">L<sub>mask</sub></i> corresponds to greater information loss (higher difficulty).
                    </li>
                    <li style="margin-bottom: 8px;">
                        We implemented a variant of this augmentation with a larger increase in side length in each step named Dynamic Contrast.
                    </li>
                </ul>
                <img src="./images/dynamic_incr.png" width=700px/>
                <img src="./images/dynamic_decr.png" width=700px/>
                <img src="./images/contrast_incr.png" width=700px/>
                <img src="./images/contrast_decr.png" width=700px/>
            </li>
        </ul>

        
        <h3>3.3 Pacing Functions</h3>
        <p>
            We implemented dynamic schedulers that adjust the augmentation parameters (<i style="font-family: serif;">N</i>, for Colorful Cutout, Size for Dynamic Cutout) as a linear function of the training epoch <i style="font-family: serif;">t</i>.
        </p>
        
        <h4>Increasing Difficulty (Curriculum)</h4>
        <p>
            For Colorful Cutout (`color_cutout_cur_incr`), we increase the exponent linearly, making the noise finer and more complex. For Dynamic Size (`cutout_dynamic_cur_incr`), we linearly increase the mask size:
        </p>
        
        <center>
            <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
              <msub>
                <mi>L</mi>
                <mtext>mask</mtext>
              </msub>
              <mo stretchy="false">(</mo>
              <mi>t</mi>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <msub>
                <mi>L</mi>
                <mtext>min</mtext>
              </msub>
              <mo>+</mo>
              <mfrac>
                <mi>t</mi>
                <msub>
                  <mi>T</mi>
                  <mtext>total</mtext>
                </msub>
              </mfrac>
              <mo>×</mo>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>L</mi>
                <mtext>max</mtext>
              </msub>
              <mo>-</mo>
              <msub>
                <mi>L</mi>
                <mtext>min</mtext>
              </msub>
              <mo stretchy="false">)</mo>
            </math>
        </center>

        <h4>Decreasing Difficulty (Anti-Curriculum)</h4>
        <p>
            For Colorful Cutout (`color_cutout_cur_decr`), we start with the highest exponent (max complexity) and decrease to 0. For Dynamic Size (`cutout_dynamic_cur_decr`), we start with the largest mask and shrink it, revealing more of the image as training converges:
        </p>
        
        <center>
            <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
              <msub>
                <mi>L</mi>
                <mtext>mask</mtext>
              </msub>
              <mo stretchy="false">(</mo>
              <mi>t</mi>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <msub>
                <mi>L</mi>
                <mtext>max</mtext>
              </msub>
              <mo>-</mo>
              <mfrac>
                <mi>t</mi>
                <msub>
                  <mi>T</mi>
                  <mtext>total</mtext>
                </msub>
              </mfrac>
              <mo>×</mo>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>L</mi>
                <mtext>max</mtext>
              </msub>
              <mo>-</mo>
              <msub>
                <mi>L</mi>
                <mtext>min</mtext>
              </msub>
              <mo stretchy="false">)</mo>
            </math>
        </center>
        
        <p>
           This allows us to test the trajectory of learning without changing the total amount of augmentation applied over the course of training.
        </p>
                <h3>3.4 Test-Time Color Robustness</h3>
        <p>
            To better understand if our curriculum strategies help the model generalize, we investigated Color Robustness. We choose color because we include Colorful Cutout as one of our augmentations, and we wanted to see if models trained with a specific difficulty trajectory are more resistant to color changes they haven't seen before.
        </p>
        <p>
            We simulated this by applying a <strong>Color Jitter</strong> transformation to the testing images on CIFAR-10 low data. This shifts the brightness, contrast, saturation, and hue without changing the image label. We used a severity scale from 1 to 5 to control how strong the shift is.
        </p>
        <ul style="margin-left: 20px; line-height: 1.6em;">
            <li style="margin-bottom: 8px;"><strong>Brightness, Contrast, Saturation:</strong> Adjusted by 0.2 &times; severity</li>
            <li style="margin-bottom: 8px;"><strong>Hue:</strong> Adjusted by 0.05 &times; severity</li>
        </ul>
        <p>
            This allows us to test if the "hard" or "easy" training schedules create features that are stable even when the image colors look different.
        </p>
        <img src="./images/color_time.png" width=700px/>
        <h3>3.5 Low-Data Regime Implementation</h3>
        <p>
            We introduced a low-data regime to investigate whether augmentation curriculum makes a measurable difference when data is scarce. This setup is designed to simulate real-world environments where quality images or other types of data are hard to collect.
        </p>
        <p>
            To implement this, we subsampled the training split to retain only a fixed fraction <i>f = 0.1</i>. Concretely, after creating the train/validation partition, we randomly sampled a subset of the training data with <code>data_fraction = 0.1</code>, utilizing a fixed random seed to ensure reproducibility across all experimental runs.
        </p>
    </div>
    <div class="margin-right-block">
        <strong>Implementation:</strong><br>
        We defined our own augmentation types in addition to Choi et al. to further compare and analyze between <code>cur_incr</code> and <code>cur_decr</code> modes.
    </div>
</div>

<div class="content-margin-container" id="experiments">
    <div class="margin-left-block"></div>
    <div class="main-content-block">
        <h1>4. Experiments & Results</h1>
        <p>
            <em>(Results pending final training runs)</em>
        </p>
        
        <p>
            We compare the test accuracy of ResNet50 on CIFAR-10 across three conditions: Static Baseline, Increasing Difficulty, and Decreasing Difficulty.
        </p>
    </div>
    <div class="margin-right-block">
        Visualizations are critical. Ensure captions explain the main takeaway of the figure.
    </div>
</div>

<div class="content-margin-container" id="discussion">
    <div class="margin-left-block"></div>
    <div class="main-content-block">
        <h1>5. Discussion</h1>
        
        <h3>5.1 Why isn’t Easy&rarr;Hard clearly better?</h3>
        <p>
            Theoretically, we might expect Easy&rarr;Hard to help early representation learning and then act as a regularizer, while Hard&rarr;Easy might hurt early optimization. However, our experiments suggest that once a good representation is found, the network is robust enough that the precise path through augmentation difficulty doesn’t matter—at least for ResNet-50 on CIFAR.
        </p>
        <p>Possible explanations include:</p>
        <ul>
            <li><strong>Dataset Complexity:</strong> CIFAR is relatively small; all curricula are strong enough to regularize but not strong enough to fundamentally distort the learning dynamics.</li>
            <li><strong>Difficulty Range:</strong> Our difficulty range may not be extreme enough to create a clear separation between "too easy" and "too hard."</li>
            <li><strong>Optimization Noise:</strong> The optimization noise (SGD stochasticity, initialization) dominates the small second-order effect of curriculum choice.</li>
        </ul>

        <h3>5.2 Interaction between Augmentation and Optimization</h3>
        <p>
            When augmentations are very strong (dynamic + contrast), some runs clearly underperform. This suggests a tri-way interaction between <strong>Augmentation Difficulty</strong>, <strong>Curriculum Schedule</strong>, and <strong>Optimizer Hyperparameters</strong> (LR schedule, batch size).
        </p>
        <p>
            We hypothesize that with better tuning (e.g., slightly lower LR when difficulty is high, or longer warmup), a more consistent benefit of Easy&rarr;Hard might emerge. Conversely, with more extreme augmentations, curriculum might matter more: Hard&rarr;Easy early epochs with heavy corruption could cause irrecoverable damage.
        </p>
        <p>
            Under conventional ResNet-50 training settings on CIFAR-10/100, the choice of augmentation curriculum direction has at most a very small effect on final test accuracy. The primary observable effect is on the distribution of outcomes (<strong>stability</strong>), not on best-case performance. Thus, for practitioners in this regime, spending effort on precise curriculum design is likely less important than robust hyperparameter tuning and choosing a reasonable base augmentation strength.
        </p>

        <h3>5.3 Limitations</h3>
        <ul>
            <li><strong>Sample Size:</strong> We used a small number of seeds per configuration due to computational constraints.</li>
            <li><strong>Scope:</strong> We limited our study to one architecture (ResNet-50) and one family of augmentations (cutout-style).</li>
            <li><strong>Hyperparameters:</strong> We did not tune hyperparameters per curriculum; they all shared the same optimizer and LR schedule.</li>
            <li><strong>Metric:</strong> We analyzed final test accuracy only, without analyzing full training curves or early-epoch behavior.</li>
        </ul>

        <h3>5.4 Future Work</h3>
        <ul>
            <li><strong>Adaptive Curriculum:</strong> Explore curricula where difficulty is adjusted based on training loss or validation accuracy rather than a fixed linear schedule.</li>
            <li><strong>Dimensions:</strong> Explore other augmentation dimensions: color jitter strength, blur, geometric distortions, or RandAugment magnitude schedules.</li>
            <li><strong>Datasets:</strong> Consider more challenging datasets or architectures, where overfitting and representation learning challenges are more severe.</li>
        </ul>

        <h3>5.5 Conclusion</h3>
        <p>
            We evaluated several curricula (increasing, decreasing, static augmentation difficulty) across different cutout-style augmentations on CIFAR-10 and CIFAR-100 with ResNet-50.
        </p>
        <p>
            Contrary to the intuitive expectation, no curriculum direction consistently outperformed the others in terms of best-case test accuracy. The main effect of strong augmentation and curricula in this regime is on <strong>training stability</strong>, not on the quality of the final solution. This suggests that, at least in this standard vision benchmark setting, augmentation curricula are a relatively second-order design choice compared to base augmentation strength.
        </p>
    </div>
    <div class="margin-right-block">
    </div>
</div>

<div class="content-margin-container" id="citations">
    <div class="margin-left-block"></div>
    <div class="main-content-block">
        <div class='citation' id="references" style="height:auto"><br>
            <span style="font-size:16px">References:</span><br><br>

            <a id="ref_1"></a>[1] He, K., et al. "Deep residual learning for image recognition." CVPR 2016.<br><br>
            
            <a id="ref_2"></a>[2] DeVries, T., & Taylor, G. W. "Improved regularization of convolutional neural networks with cutout." arXiv 2017.<br><br>
            
            <a id="ref_3"></a>[3] Bengio, Y., et al. "Curriculum learning." ICML 2009.<br><br>

            <a id="ref_4"></a>[4] Frolov, S., et al. "ObjBlur: A Curriculum Learning Approach With Progressive Object-Level Blurring." arXiv 2024.<br><br>

            <a id="ref_5"></a>[5] Yang, S., et al. "EntAugment: Entropy-Driven Adaptive Data Augmentation Framework." arXiv 2024.<br><br>

            <a id="ref_6"></a>[6] Maltser, R. "Augmentation Curriculum Learning." Master's Thesis, Hebrew University of Jerusalem, 2025.<br><br>

            <a id="ref_7"></a>[7] Choi, J., & Kim, Y. "Colorful Cutout: Enhancing Image Data Augmentation with Curriculum Learning." ICLR Tiny Papers 2024.<br><br>
            
            <a id="ref_8"></a>[8] Krizhevsky, A., et al. "Learning multiple layers of features from tiny images." 2009.<br><br>

            <a id="ref_9"></a>[9] Wei, J., et al. "Few-Shot Text Classification with Triplet Networks, Data Augmentation, and Curriculum Learning." NAACL 2021.<br><br>

        </div>
    </div>
    <div class="margin-right-block"></div>
</div>

</body>
</html>