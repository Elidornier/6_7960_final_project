<!DOCTYPE html>
<html>
<head>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
<link rel="shortcut icon" href="images/icon.ico">
<style type="text/css">
    /* 1. BASIC PAGE SETUP */
    body {
        background-color: #ffffff; /* Clean white background */
        color: #333333; /* Dark gray text is easier on eyes than pitch black */
        font-family: "Georgia", "Times New Roman", serif; /* Serif font for the main reading */
        font-size: 20px; /* Distill uses large, readable text */
        line-height: 1.6em; /* More breathing room between lines */
        margin: 0;
    }

    /* 2. LINKS (Blue) */
    a:link, a:visited {
        color: #2e6db2; 
        text-decoration: none;
        border-bottom: 1px solid #e0e0e0; /* Subtle underline */
    }
    a:hover {
        color: #1a4e85;
        border-bottom: 2px solid #1a4e85;
    }

    /* 3. LAYOUT GRID */
    .content-margin-container {
        display: flex;
        width: 100%;
        justify-content: center;
        align-items: flex-start; /* Aligns content to top */
        margin-bottom: 20px;
    }

    /* 4. MAIN COLUMN (Narrower for readability) */
    .main-content-block {
        width: 55%; 
        max-width: 720px; /* Optimal reading width */
        background-color: #fff;
        padding: 0px;
        /* We REMOVED the borders here */
        border: none; 
    }

    /* 5. MARGIN NOTES */
    .margin-left-block {
        width: 20%;
        max-width: 180px;
        margin-right: 30px;
        text-align: right;
        font-size: 14px;
        color: #6b6b6b;
        font-family: "HelveticaNeue-Light", "Helvetica Neue", sans-serif; /* Sidenotes stay sans-serif */
        line-height: 1.4em;
    }

    .margin-right-block {
        width: 20%;
        max-width: 220px; /* Slightly wider right margin */
        margin-left: 30px;
        text-align: left;
        font-size: 13px;
        color: #6b6b6b;
        font-family: "HelveticaNeue-Light", "Helvetica Neue", sans-serif;
        line-height: 1.4em;
    }

    /* 6. HEADERS */
    h1, h2, h3 {
        font-family: "HelveticaNeue-Light", "Helvetica Neue", Helvetica, Arial, sans-serif;
        color: #000;
        margin-top: 50px;
        margin-bottom: 15px;
        font-weight: 600;
        line-height: 1.2em;
    }
    h1 { font-size: 36px; letter-spacing: -0.5px; } /* Big section headers */
    h2 { font-size: 26px; border-bottom: 1px solid #eee; padding-bottom: 10px; }
    h3 { font-size: 20px; font-weight: 600; margin-top: 30px;}

    /* 7. IMAGES & CAPTIONS */
    img, .my-video {
        max-width: 100%;
        height: auto;
        display: block;
        margin: 20px auto;
        border-radius: 4px; 
        box-shadow: 0 4px 10px rgba(0,0,0,0.05); /* Subtle shadow for images */
    }

    /* 8. MATH & CODE */
    .mathjax-mobile, .mathml-non-mobile { display: none; }
    .show-mathml .mathml-non-mobile { display: block; }
    .show-mathjax .mathjax-mobile { display: block; }
    
    code {
        background-color: #f4f4f4;
        padding: 2px 5px;
        border-radius: 3px;
        font-family: "Courier New", Courier, monospace;
        font-size: 0.9em;
    }

    /* 9. CITATION BLOCK */
    div.citation {
        font-family: "HelveticaNeue-Light", "Helvetica Neue", sans-serif;
        font-size: 14px;
        background-color: #f7f7f7;
        padding: 20px;
        border-radius: 5px;
        border: 1px solid #eee;
    }

    /* 10. TITLE HEADER TABLE SPECIFIC */
    table.header {
        width: 100%;
        max-width: 100%;
    }

    /* 11. TOP NAVIGATION BAR */
    .nav-header {
        background-color: #23374d; /* Navy Blue */
        width: 100%;
        display: flex;
        justify-content: center;
        padding: 15px 0;
        font-family: "HelveticaNeue-Light", "Helvetica Neue", Helvetica, Arial, sans-serif;
        border-bottom: 1px solid rgba(0,0,0,0.1);
    }
    
    .nav-inner {
        width: 90%; 
        max-width: 1080px; /* Matches the width of the article content */
        display: flex;
        justify-content: space-between;
        align-items: center;
    }

    .nav-logo {
        font-weight: 600;
        font-size: 18px;
        color: white !important; /* Force white text */
        border-bottom: none !important; /* Remove underline */
        display: flex;
        align-items: center;
    }

    .nav-links a {
        color: rgba(255,255,255,0.7) !important; /* Slightly transparent white */
        margin-left: 25px;
        font-size: 12px;
        font-weight: 500;
        text-transform: uppercase; /* MAKES TEXT CAPS */
        letter-spacing: 0.5px;
        border-bottom: none !important;
        transition: color 0.2s;
    }

    .nav-links a:hover {
        color: #ffffff !important; /* Bright white on hover */
    }

</style>

<title>Trajectory of Augmentation Difficulty</title>
<meta property="og:title" content="Trajectory of Augmentation Difficulty" />
<meta charset="UTF-8">
</head>

<body>

<div class="nav-header">
    <div class="nav-inner">
        <a href="#" class="nav-logo">
            <span class="logo-icon"></span> 6.7960 Project
        </a>
        
        <div class="nav-links">
            <a href="#">About</a>
            <a href="#">Paper</a>
            <a href="#">Code</a>
            <a href="#">Team</a>
        </div>
    </div>
</div>

<div class="content-margin-container" style="margin-top: 60px; margin-bottom: 60px;">
    <div class="margin-left-block"></div>
    <div class="main-content-block">
        <h1 style="font-size: 50px; line-height: 1.1em; margin-bottom: 20px; font-family: 'Helvetica Neue', Helvetica, sans-serif;">
            Investigating the Trajectory<br>of Augmentation Difficulty
        </h1>
        
        <div style="font-family: 'Helvetica Neue', sans-serif; font-size: 18px; color: #555;">
            <p>
                <a href="#">Alice Xiao (UG)</a>, 
                <a href="#">Aimee Yu (UG)</a>, 
                <a href="#">Celinda Zhu (UG)</a>
            </p>
            <p style="font-size: 15px; color: #888;">
                Final Project for 6.7960, MIT &bull; Fall 2025
            </p>
        </div>
    </div>
    <div class="margin-right-block"></div>
</div>


<div class="content-margin-container" id="intro">
    <div class="margin-left-block">
        <div style="position:fixed; max-width:inherit; top:max(20%,120px)">
            <b style="font-size:16px">Outline</b><br><br>
            <a href="#intro">Introduction</a><br><br>
            <a href="#related_work">Related Work</a><br><br>
            <a href="#methodology">Methodology</a><br><br>
            <a href="#experiments">Experiments & Results</a><br><br>
            <a href="#discussion">Discussion</a><br><br>
        </div>
    </div>
    <div class="main-content-block">
        <h1>1. Introduction</h1>
        
        <h3>Motivation</h3>
        <p>
            Deep learning's remarkable success in computer vision can be attributed in large part to the capacity of powerful, over-parameterized models such as ResNet <a href="#ref_1">[1]</a> to generalize effectively beyond their training data. Consequently, Data Augmentation has emerged as a cornerstone technique to bridge the generalization gap, artificially expanding the training distribution through stochastic transformations like blurring, cropping, and occlusion.
        </p>
        <p>
            In our previous homework, we explored the critical role of data augmentation in enhancing model performance and shaping representation with implemented transformations such as <code>RandomHorizontalFlip</code> and <code>RandomCrop</code> on the CIFAR-10 dataset. Through this, we observed that while augmentation made fitting the training data more challenging, it could effectively reduce overfitting and improve validation and test accuracy, demonstrating better generalization. Motivated by these findings on how data manipulation fundamentally alters the decision boundaries and distinct properties of learned features, we decided to dig deeper into this topic.
        </p>
        <p>
            However, standard data augmentation pipelines typically treat the training process as static. Augmentations are applied with random magnitudes drawn from a fixed distribution, regardless of the model's current learning state. This creates a fundamental misalignment between the data and the model:
        </p>
        <ul style="margin-left: 20px; line-height: 1.6em;">
            <li style="margin-bottom: 10px;">
                In <strong>early training stages</strong>, the model is trying to learn basic, low-level features like edges or shapes. Strong augmentations (such as massive cutout holes or high-frequency noise) might introduce excessive information loss, essentially "blinding" the model before it can see.
            </li>
            <li>
                In <strong>later training stages</strong>, the model has likely memorized the training data. Weak augmentations may fail to provide sufficient regularization, leading to overfitting.
            </li>
        </ul>
        <p>
            We hypothesize that the trajectory of difficulty is just as critical as the difficulty itself. Just as a human student would struggle if handed a complex calculus problem on day one, a neural network might struggle to converge if the signal-to-noise ratio is too low at initialization.
        </p>

        <h3>Curriculum Learning</h3>
        <p>
            Curriculum Learning, as proposed by Bengio et al. <a href="#ref_3">[3]</a>, formalizes this intuition. It suggests that models learn more effectively when samples are presented in a meaningful order of increasing difficulty ("Easy-to-Hard"). Recent adaptive frameworks like EntAugment <a href="#ref_5">[5]</a> and ObjBlur <a href="#ref_4">[4]</a> have successfully applied this principle to data augmentation.
        </p>
        <p>
            Conversely, a counter-intuitive line of research suggests an "Anti-Curriculum" (Hard-to-Easy) approach. Theoretical work by Maltser <a href="#ref_6">[6]</a> indicates that exposing models to difficult, strongly augmented samples early on might force the learning of more robust, shape-invariant features. By front-loading the difficulty, the model may be prevented from learning "shortcuts" (like superficial texture bias) during its initial phase of high plasticity.
        </p>

        <h3>Our Contribution</h3>
        <p>
            In this work, we systematically investigate the <strong>trajectory of difficulty</strong> in data augmentation. We do not merely ask <em>if</em> curriculum learning helps; we ask <em>which trajectory</em> is optimal. We define our core question: <em>Should augmentation difficulty increase or decrease over training, and does the direction of this curriculum significantly affect generalization on CIFAR-10/100?</em>
        </p>
        
        <p>We explore two distinct axes of difficulty:</p>
        <ol style="margin-left: 20px; line-height: 1.6em;">
            <li style="margin-bottom: 10px;">
                <strong>Complexity-based:</strong> Using Colorful Cutout <a href="#ref_7">[7]</a> to vary the information entropy of the occluded region.
            </li>
            <li>
                <strong>Occlusion-based:</strong> Using Dynamic Cutout Size, a method we implemented to vary the spatial extent of information loss.
            </li>
        </ol>

        <p>and compare three distinct training regimes:</p>
        <ol style="margin-left: 20px; line-height: 1.6em;">
            <li style="margin-bottom: 10px;">
                <strong>Static Baseline:</strong> Random augmentation magnitude (Standard practice).
            </li>
            <li style="margin-bottom: 10px;">
                <strong>Curriculum (Easy &rarr; Hard):</strong> Gradually increasing complexity/occlusion.
            </li>
            <li>
                <strong>Anti-Curriculum (Hard &rarr; Easy):</strong> Gradually decreasing complexity/occlusion.
            </li>
        </ol>

        <p>
            By training ResNet50 architectures on CIFAR-10 and CIFAR-100 under these varying dynamics, we aim to decouple the impact of augmentation type from augmentation scheduling.
        </p>
    </div>
    <div class="margin-right-block">
        <div style="margin-bottom: 20px;">
            <strong>Hypothesis:</strong><br>
            Does early exposure to "hard" augmentations (Anti-Curriculum) induce better robustness than the traditional "Easy-to-Hard" Curriculum?
        </div>
    </div>
</div>

<div class="content-margin-container" id="related_work">
    <div class="margin-left-block"></div>
    <div class="main-content-block">
        <h1>2. Related Work</h1>
        <p>
            Recent research has pivoted toward <strong>adaptive</strong> strategies that integrate curriculum learning: models learn faster and better when training examples are ordered from easy to hard <a href="#ref_3">[3]</a>.
        </p>
        <ul>
            <li><strong>ObjBlur <a href="#ref_4">[4]</a>:</strong> Introduces a curriculum for layout-to-image generation by progressively moving from strong blurring (low-frequency signals) to cleaner images (high-frequency details).</li>
            <li><strong>EntAugment <a href="#ref_5">[5]</a>:</strong> Proposes a tuning-free framework that adapts augmentation magnitude based on sample difficulty. It utilizes an entropy-based metric to assess model confidence, applying lighter augmentations to hard samples early in training and intensifying the magnitude as the model generalizes.</li>
        </ul>

        <h3>Magnitude-Based Scheduling</h3>
        <p>
            A key subset of Curriculum Data Augmentation focuses specifically on scheduling the <strong>intensity</strong> or <strong>magnitude</strong> of transformations. Wei et al. (2021) demonstrated that gradually increasing the magnitude of distortions (e.g., rotation angle, shear intensity) correlates with improved generalization <a href="#ref_9">[9]</a>.
        </p>
        <p>
            In the context of occlusion methods, this magnitude corresponds directly to the <strong>size</strong> of the erased region. While early occlusion methods like Cutout <a href="#ref_2">[2]</a> and Random Erasing utilized fixed or randomly sampled sizes, later works such as Hide-and-Seek highlighted the delicate balance required between occlusion and feature retention. Our <strong>Dynamic Cutout Size</strong> implementation serves as a direct instantiation of magnitude-based curriculum for occlusion: we explicitly schedule the bounding box dimension ($W \times H$) as a function of the training epoch.
        </p>

        <h3>Directionality</h3>
        <p>
            Finally, a critical, yet under-explored question is the <strong>trajectory</strong> of augmentation difficulty. While standard CL dictates an "Easy-to-Hard" schedule, recent work by Maltser on <strong>Augmentation Curriculum Learning (ACL)</strong> investigates alternative pacing, including "Anti-Curriculum" (Hard-to-Easy) strategies <a href="#ref_6">[6]</a>. Maltser's findings suggest that explicitly scoring and ordering augmentations can outperform random selection, but the optimal direction remains a subject of debate.
        </p>
        <p>
            In this project, we utilize <strong>Colorful Cutout</strong> <a href="#ref_7">[7]</a> to test these conflicting hypotheses. By progressively dividing the erasure box into smaller sub-regions, Colorful Cutout allows us to control the "complexity" of the noise. As the number of sub-regions increases, the sample becomes more "tangled" and difficult, naturally forming a difficulty gradient that we can invert or scale.
        </p>
    </div>
    <div class="margin-right-block">
        <strong>Key Concept:</strong><br>
        <em>Magnitude Scheduling</em>: Varying the intensity (size) of an augmentation over time.
    </div>
</div>

<div class="content-margin-container" id="methodology">
    <div class="margin-left-block"></div>
    <div class="main-content-block">
        <h1>3. Methodology</h1>
        
        <h3>3.1 Setup</h3>
        <p>
            To isolate the effect of the curriculum, we needed a rigorously controlled environment. We didn't want model capacity or hyperparameter tuning to affect the result, so we kept the training recipe the same across augmentations.
        </p>
        <ul style="margin-left: 20px; line-height: 1.6em;">
            <li style="margin-bottom: 10px;"><strong>Task:</strong> Supervised image classification.</li>
            <li style="margin-bottom: 10px;"><strong>Datasets:</strong> We evaluated performance on CIFAR-10 and CIFAR-100. CIFAR images (32×32) are resized to 256×256 then cropped to 244×244 and normalized for ResNet-50. We tested two distinct data availability regimes:
                <ul style="margin-top: 5px; margin-bottom: 5px; list-style-type: circle;">
                    <li><strong>Full Data:</strong> We use the entire training split after the train/validation partition.</li>
                    <li><strong>Low-Data (10%):</strong> We subsample the training split to retain only a fixed fraction <i>f=0.1</i>.</li>
                </ul>
            </li>
            <li><strong>Model:</strong> ResNet-50.</li>
            <li><strong>Metric:</strong> Classification accuracy.</li>
        </ul>
        
        <p>
            Given an input image <i style="font-family: serif;">x</i> &in; &#8477;<sup>3 &times; H &times; W</sup>, the backbone produces a feature tensor which we globally pool and flatten into a vector <i style="font-family: serif;">h</i> &in; &#8477;<sup>d</sup>. The final prediction layer is a small MLP classifier. We train the model to minimize cross-entropy loss with label smoothing to mitigate overconfidence.
        </p>

        <h3>3.2 Augmentations</h3>
        <p>
            We investigated two types of augmentation. Each has a difficulty level we can change during training.
        </p>

        <ul style="list-style-type: disc; margin-left: 20px;">
            
            <li style="margin-bottom: 25px;">
                <strong>A. Colorful Cutout (Complexity-based Difficulty)</strong>
                <div style="margin-top: 5px; margin-bottom: 10px;">
                    This augmentation is implemented based on the Colorful Cutout; this places a single box of random noise over the image.
                </div>
                <ul style="list-style-type: circle; margin-left: 20px;">
                    <li style="margin-bottom: 8px;">
                        <strong>Mechanism:</strong> For a bounding box of size <i style="font-family: serif;">B</i>, we define a <code>region_size</code> <i style="font-family: serif;">S</i>. The box is divided into (<i style="font-family: serif;">B/S</i>)<sup>2</sup> sub-squares. Each sub-square is filled with a random color.
                    </li>
                    <li style="margin-bottom: 8px;">
                        <strong>Difficulty Metric:</strong> As <i style="font-family: serif;">S</i> decreases, the number of sub-regions increases, creating higher-frequency color noise (higher entropy).
                    </li>
                    <li style="margin-bottom: 8px;">
                        <strong>Code Implementation:</strong>
                        <div style="margin: 10px 0; text-align: left; padding-left: 20px;">
                             <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
                              <mi>S</mi>
                              <mo>=</mo>
                              <mfrac>
                                <mi>B</mi>
                                <msup>
                                  <mn>2</mn>
                                  <mtext>exponent</mtext>
                                </msup>
                              </mfrac>
                            </math>
                        </div>
                        Where <code>exponent</code> is the curriculum variable controlled by the epoch index.
                    </li>
                </ul>
            </li>
            <img src="./images/color_incr.png" width=700px/>
            <img src="./images/color_decr.png" width=700px/>
            <li style="margin-bottom: 25px;">
                <strong>B. Dynamic Cutout Size (Occlusion-based Difficulty)</strong>
                <div style="margin-top: 5px; margin-bottom: 10px;">
                    This method varies the spatial extent of the occlusion. We dynamically calculate the side length of the square mask, <i style="font-family: serif;">L<sub>mask</sub></i>, based on the current epoch.
                </div>
                <ul style="list-style-type: circle; margin-left: 20px;">
                    <li style="margin-bottom: 8px;">
                        <strong>Mechanism:</strong> We linearly interpolate the mask size between a minimum (<i style="font-family: serif;">L<sub>min</sub></i>) and maximum (<i style="font-family: serif;">L<sub>max</sub></i>) value.
                    </li>
                    <li style="margin-bottom: 8px;">
                        <strong>Difficulty Metric:</strong> Larger <i style="font-family: serif;">L<sub>mask</sub></i> corresponds to greater information loss (higher difficulty).
                    </li>
                    <li style="margin-bottom: 8px;">
                        We implemented a variant of this augmentation with a larger increase in side length in each step named Dynamic Contrast.
                    </li>
                </ul>
                <img src="./images/dynamic_incr.png" width=700px/>
                <img src="./images/dynamic_decr.png" width=700px/>
                <img src="./images/contrast_incr.png" width=700px/>
                <img src="./images/contrast_decr.png" width=700px/>
            </li>
        </ul>

        
        <h3>3.3 Pacing Functions</h3>
        <p>
            We implemented dynamic schedulers that adjust the augmentation parameters (<i style="font-family: serif;">N</i>, for Colorful Cutout, Size for Dynamic Cutout) as a linear function of the training epoch <i style="font-family: serif;">t</i>.
        </p>
        
        <h4>Increasing Difficulty (Curriculum)</h4>
        <p>
            For Colorful Cutout (`color_cutout_cur_incr`), we increase the exponent linearly, making the noise finer and more complex. For Dynamic Size (`cutout_dynamic_cur_incr`), we linearly increase the mask size:
        </p>
        
        <center>
            <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
              <msub>
                <mi>L</mi>
                <mtext>mask</mtext>
              </msub>
              <mo stretchy="false">(</mo>
              <mi>t</mi>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <msub>
                <mi>L</mi>
                <mtext>min</mtext>
              </msub>
              <mo>+</mo>
              <mfrac>
                <mi>t</mi>
                <msub>
                  <mi>T</mi>
                  <mtext>total</mtext>
                </msub>
              </mfrac>
              <mo>×</mo>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>L</mi>
                <mtext>max</mtext>
              </msub>
              <mo>-</mo>
              <msub>
                <mi>L</mi>
                <mtext>min</mtext>
              </msub>
              <mo stretchy="false">)</mo>
            </math>
        </center>

        <h4>Decreasing Difficulty (Anti-Curriculum)</h4>
        <p>
            For Colorful Cutout (`color_cutout_cur_decr`), we start with the highest exponent (max complexity) and decrease to 0. For Dynamic Size (`cutout_dynamic_cur_decr`), we start with the largest mask and shrink it, revealing more of the image as training converges:
        </p>
        
        <center>
            <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
              <msub>
                <mi>L</mi>
                <mtext>mask</mtext>
              </msub>
              <mo stretchy="false">(</mo>
              <mi>t</mi>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <msub>
                <mi>L</mi>
                <mtext>max</mtext>
              </msub>
              <mo>-</mo>
              <mfrac>
                <mi>t</mi>
                <msub>
                  <mi>T</mi>
                  <mtext>total</mtext>
                </msub>
              </mfrac>
              <mo>×</mo>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>L</mi>
                <mtext>max</mtext>
              </msub>
              <mo>-</mo>
              <msub>
                <mi>L</mi>
                <mtext>min</mtext>
              </msub>
              <mo stretchy="false">)</mo>
            </math>
        </center>
        
        <p>
           This allows us to test the trajectory of learning without changing the total amount of augmentation applied over the course of training.
        </p>
                <h3>3.4 Test-Time Color Robustness</h3>
        <p>
            To better understand if our curriculum strategies help the model generalize, we investigated Color Robustness. We choose color because we include Colorful Cutout as one of our augmentations, and we wanted to see if models trained with a specific difficulty trajectory are more resistant to color changes they haven't seen before.
        </p>
        <p>
            We simulated this by applying a <strong>Color Jitter</strong> transformation to the testing images on CIFAR-10 low data. This shifts the brightness, contrast, saturation, and hue without changing the image label. We used a severity scale from 1 to 5 to control how strong the shift is.
        </p>
        <ul style="margin-left: 20px; line-height: 1.6em;">
            <li style="margin-bottom: 8px;"><strong>Brightness, Contrast, Saturation:</strong> Adjusted by 0.2 &times; severity</li>
            <li style="margin-bottom: 8px;"><strong>Hue:</strong> Adjusted by 0.05 &times; severity</li>
        </ul>
        <p>
            This allows us to test if the "hard" or "easy" training schedules create features that are stable even when the image colors look different.
        </p>
        <img src="./images/color_time.png" width=700px/>
        <h3>3.5 Low-Data Regime Implementation</h3>
        <p>
            We introduced a low-data regime to investigate whether augmentation curriculum makes a measurable difference when data is scarce. This setup is designed to simulate real-world environments where quality images or other types of data are hard to collect.
        </p>
        <p>
            To implement this, we subsampled the training split to retain only a fixed fraction <i>f = 0.1</i>. Concretely, after creating the train/validation partition, we randomly sampled a subset of the training data with <code>data_fraction = 0.1</code>, utilizing a fixed random seed to ensure reproducibility across all experimental runs.
        </p>
    </div>
    <div class="margin-right-block">
        <strong>Implementation:</strong><br>
        We defined our own augmentation types in addition to Choi et al. to further compare and analyze between <code>cur_incr</code> and <code>cur_decr</code> modes.
    </div>
</div>

<div class="content-margin-container" id="experiments">
    <div class="margin-left-block"></div>
    <div class="main-content-block">
        <style>
            /* LaTeX-style Table CSS */
            table.academic-table {
                width: 100%;
                border-collapse: collapse;
                margin: 20px 0;
                font-family: "Georgia", serif;
                font-size: 15px;
                color: #333;
            }
            table.academic-table th {
                border-top: 2px solid #333;
                border-bottom: 1px solid #333;
                padding: 10px;
                text-align: center;
                font-weight: 600;
                background-color: #fff;
            }
            table.academic-table td {
                padding: 8px;
                text-align: center;
                border: none;
            }
            /* Bottom border for the last row */
            table.academic-table tr:last-child td {
                border-bottom: 2px solid #333;
            }
            /* Left-align the first column */
            table.academic-table td:first-child, table.academic-table th:first-child {
                text-align: left;
                padding-left: 15px;
            }
            /* Alternating row colors for readability if desired, currently plain white */
        </style>

        <h1>4. Experiments & Results</h1>
        <p>
            We now turn to the empirical question: given the same model, optimizer, and base recipe, how much does it matter whether augmentation difficulty increases or decreases over time? We break this analysis into three parts:
        </p>
        <ol style="margin-left: 20px; line-height: 1.6em;">
            <li style="margin-bottom: 8px;"><strong>Overall Performance:</strong> Does curriculum direction affect standard test accuracy?</li>
            <li style="margin-bottom: 8px;"><strong>Data Availability:</strong> Does the impact of curriculum change when training data is scarce?</li>
            <li style="margin-bottom: 8px;"><strong>Color Robustness:</strong> Does a specific difficulty trajectory make the model more robust to unseen color shifts?</li>
        </ol>
        <p>
            Throughout this section, all numbers are top-1 test accuracies. We separate full-data and low-data regimes and never compare them directly.
        </p>

        <h3>4.1 Overall performance</h3>

        <h3>The Full-Data Regime</h3>
        <p>
            When the model has access to all 50,000 training images, the specific curriculum matters less, and the no curriculum baseline (with a single random color cutout size 32&times;32) is surprisingly hard to beat.
        </p>

        <p><strong>CIFAR-10 (Full Data)</strong></p>
        <p>
            Performance was tightly clustered. The differences here are minute, suggesting that for easy tasks with ample data, the schedule is largely irrelevant.
        </p>
        <div style="text-align: center; margin: 20px 0;">
             
        </div>
        <ul style="margin-left: 20px; line-height: 1.6em;">
            <li style="margin-bottom: 8px;"><strong>Best Performance:</strong> Colorful Cutout No Curriculum (95.64%)</li>
            <li style="margin-bottom: 8px;"><strong>Trend:</strong> The static baseline slightly outperformed both increasing and decreasing schedules.</li>
            <img src="./images/c10_train_dots.png" width=580px/>
            <img src="./images/c10_val_dots.png" width=580px/>
        </ul>
        <p>
            Dynamic Contrast performed worst here, likely because the aggressive maximum box size (150 pixels) occluded too much of the 244&times;244 image, destroying necessary features.
        </p>

        <p><strong>CIFAR-100 (Full Data)</strong></p>
        <p>
            Similar trends appeared in the harder CIFAR-100 task.
        </p>
        <div style="text-align: center; margin: 20px 0;">
        </div>
        <ul style="margin-left: 20px; line-height: 1.6em;">
            <li style="margin-bottom: 8px;"><strong>Best Performance:</strong> Colorful Cutout No Curriculum (81.36%)</li>
            <li style="margin-bottom: 8px;"><strong>Trend:</strong> Similarly, the static baseline slightly outperformed both increasing and decreasing schedules.</li>
            <img src="./images/c100_train_dots.png" width=580px/>
            <img src="./images/c100_val_dots.png" width=580px/>
        </ul>
        <p>
            In data-rich regimes, a well-tuned static augmentation is a very strong baseline. Complex schedules often fail to provide a significant lift.
        </p>
        <p>
            At a high level: in the full-data regime, all ‘reasonable’ augmentations are clustered tightly, and the Colorful Cutout No Curriculum augmentation is already very hard to beat. Curriculums are small addons on top of an already strong recipe, and they don’t help in our current set up. In the low-data regime, curriculums can shift performance by up to 0.5–0.8% within a family, and overly aggressive dynamic schedules can hurt dramatically.
        </p>

        <h3>The Low-Data Regime (10% Data)</h3>
        <p>
            We want to investigate when data is scarce, whether augmentation curriculum makes a measurable difference.
        </p>

        <p><strong>CIFAR-10 (10% Data)</strong></p>
        <ul style="margin-left: 20px; line-height: 1.6em;">
            <li style="margin-bottom: 8px;"><strong>Winner:</strong> Colorful Cutout Decreasing Difficulty (91.06%)</li>
            <li style="margin-bottom: 8px;"><strong>Trend:</strong> We observed a weak pattern where Decreasing > Increasing > Static.</li>
        </ul>

        <p><strong>CIFAR-100 (10% Data)</strong></p>
        <p>This was our most challenging setting—hard task, scarce data.</p>

        <table class="academic-table">
            <thead>
                <tr>
                    <th>Augmentation Family</th>
                    <th>Easy &rarr; Hard</th>
                    <th>Hard &rarr; Easy</th>
                    <th>No Curriculum</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Colorful Cutout</td>
                    <td>64.08%</td>
                    <td>64.72%</td>
                    <td>63.95%</td>
                </tr>
                <tr>
                    <td>Dynamic Cutout</td>
                    <td>61.36%</td>
                    <td>61.72%</td>
                    <td>63.95%</td>
                </tr>
                <tr>
                    <td>Dynamic Contrast</td>
                    <td>55.98%</td>
                    <td>57.01%</td>
                    <td>63.95%</td>
                </tr>
            </tbody>
        </table>

        <img src="./images/c10_full.png" width=750px/>
        <img src="./images/c100_full.png" width=750px/>

        <p><strong>Key Observations</strong></p>
        <ol style="margin-left: 20px; line-height: 1.6em;">
            <li style="margin-bottom: 15px;">
                <strong>Hard-to-Easy consistently beats Easy-to-Hard:</strong> The table shows that regardless of the specific augmentation method, the Decreasing schedule consistently yielded higher accuracy. We believe this "Hard-to-Easy" trajectory works better in data-scarce environments because it mitigates overfitting through two distinct phases:
                <ul style="margin-top: 8px; list-style-type: circle;">
                    <li style="margin-bottom: 5px;"><strong>Phase 1: Anti-Memorization.</strong> By starting with the most difficult augmentations, the model is prevented from memorizing simple pixel patterns early on. It is forced to struggle and learn only the most robust, high-level features that survive heavy occlusion.</li>
                    <li><strong>Phase 2: Refinement.</strong> As training progresses, the difficulty is dialed back. This allows the model to "see" cleaner data and refine its decision boundaries using the robust features learned in Phase 1.</li>
                </ul>
                <p style="margin-top: 8px;">In contrast, the "Increasing" schedule allows the model to memorize clean images early (when the learning rate is high), only to be hit with heavy occlusion later when the learning rate is too low to effectively adapt.</p>
            </li>
            
            <li style="margin-bottom: 15px;">
                <strong>Regularization vs. Destruction:</strong> The "Dynamic Contrast" family showed significantly lower performance compared to the other groups. This is likely because the "Contrast" variant allows the occlusion box to grow up to 150 pixels. On a 32&times;32 CIFAR image, this effectively wipes out the entire input. This extreme setting highlights why the Decreasing schedule helps. An "Easy-to-Hard" schedule introduces this total destruction at the end of training, likely confusing the model just as it tries to converge. A "Hard-to-Easy" schedule treats this as extreme initial noise—forcing the model to learn from whatever scraps of pixels remain—which is then relaxed to allow fine-tuning on clearer data.
            </li>

            <li style="margin-bottom: 15px;">
                <strong>The "Safety Net" of Colorful Cutout:</strong> Standard Colorful Cutout remained the most robust family overall, achieving the highest absolute accuracy (~64.7%). Its constraints (smaller box sizes compared to the Dynamic variants) likely prevented it from being too destructive, making it a safer default choice for low-data regimes even without a perfect curriculum.
            </li>
        </ol>

        <h3>4.2 Color Robustness Results</h3>
        <p>
            We looked at the CIFAR-10 Low Data (10%) regime to compare how well different schedules handle color shifts. When there is no color shift, our previous results showed that the Decreasing (Hard &rarr; Easy) schedule was the most accurate. However, on color-shifted data, this relationship completely flipped.
        </p>
        <p>
            First, the No Curriculum (Static) baseline achieved the highest robustness overall with 38.14% accuracy. Second, among the curriculums, the Increasing (Easy &rarr; Hard) schedule consistently beat the Decreasing schedule. This was most obvious in Dynamic Cutout, where Increasing (35.07%) beat Decreasing (27.99%) by a large margin. Similar trends held for Dynamic Contrast (30.42% vs 28.12%) and Colorful Cutout (30.88% vs 30.07%).
        </p>
        <img src="./images/shift.png" width=750px/>
        <p>We identify three insights based on the findings:</p>
        <ol style="margin-left: 20px; line-height: 1.6em;">
            <li style="margin-bottom: 15px;">
                We initially thought Colorful Cutout would improve color robustness because it introduces random colors during training. However, it failed to beat the baseline. This is likely because Colorful Cutout introduces "local" noise (a small pixelated box), whereas our test applies a "global" shift (like changing the lighting of the whole scene). Learning to ignore a small, noisy box does not teach the model to handle global color changes.
            </li>
            <li style="margin-bottom: 15px;">
                The reversal on performance between Increasing and Decreasing schedules is likely due to how training ends. The Decreasing schedule ends with "easy," clean images. This allows the model to memorize the specific colors of the training data, boosting clean accuracy but making it brittle to changes. The Increasing schedule ends with "hard," heavily occluded images. This likely prevents the model from relying on simple color cues and forces it to learn more robust shapes, which works better when colors change.
            </li>
            <li>
                The fact that the Static baseline won suggests that a consistent training environment is better for robustness. Curriculum learning helps the model specialize in the specific training task, but this specialization comes at the cost of flexibility. A static approach keeps the difficulty constant, preventing the model from over-optimizing for either the "hard" start or the "easy" finish.
            </li>
        </ol>
    </div>
    <div class="margin-right-block">
        <div style="margin-bottom: 20px;">
            <strong>Takeaway:</strong><br>
            In data-scarce regimes, the "Hard-to-Easy" trajectory consistently outperforms, likely by forcing early feature robustness.
        </div>
    </div>
</div>

<div class="content-margin-container" id="discussion">
    <div class="margin-left-block"></div>
    <div class="main-content-block">
        <h1>5. Discussion</h1>
        <p>
            Our experiments were designed to test the intuitive belief that "Easy-to-Hard" is the optimal way to learn. The data suggests the reality is much more nuanced.
        </p>

        <h3>Limitations</h3>
        <ul style="margin-left: 20px; line-height: 1.6em;">
            <li style="margin-bottom: 15px;">
                <strong>Sample Size:</strong> We used a limited number of random seeds per configuration due to computational constraints. While the trends in the low-data regime were consistent, running larger-scale trials would be necessary to verify statistical significance.
            </li>
            <li style="margin-bottom: 15px;">
                <strong>Scope:</strong> We limited our study to one architecture (ResNet-50) and one family of augmentations (cutout-style). Other architectures (such as Vision Transformers) or augmentation types (such as geometric distortions or Mixup) might respond differently to curriculum learning.
            </li>
            <li style="margin-bottom: 15px;">
                <strong>Epoch:</strong> Following the protocol established by Choi et al. (ICLR 2024), we restricted training to only 5 epochs. While this standardizes the computational budget, it may prevent models from reaching full convergence and doesn’t support oscillation of augmentation difficulty, potentially obscuring long-term training dynamics or effects that emerge only after extended training periods.
            </li>
        </ul>

        <h3>Future Work</h3>
        <p>We plan to extend this study in four key directions:</p>
        <ul style="margin-left: 20px; line-height: 1.6em;">
            <li style="margin-bottom: 15px;">
                <strong>Dimensions:</strong> Applying curricula to other augmentation types, such as geometric distortions, blur, or Mixup.
            </li>
            <li style="margin-bottom: 15px;">
                <strong>Datasets:</strong> Evaluating on benchmarks like CIFAR-C or fine-grained datasets to better assess robustness and subtle feature learning.
            </li>
            <li style="margin-bottom: 15px;">
                <strong>Size Robustness:</strong> Investigating whether local occlusion curricula confer robustness to global scale shifts, to determine if the trade-offs observed in our color experiments hold for object size.
            </li>
            <li style="margin-bottom: 15px;">
                <strong>Adaptive Curriculum:</strong> Investigating schedules where difficulty adjusts dynamically based on model performance rather than a fixed timeline.
            </li>
        </ul>

        <h3>Conclusion</h3>
        <p>
            Our experiments were designed to test the intuitive belief that "Easy-to-Hard" is the optimal way to learn, but the data suggests a more nuanced reality.
        </p>
        <p>
            Overall, the static "No Curriculum" baseline generally worked best. In full-data regimes, all methods show similar accuracy; this is likely because ResNet-50 already achieves high performance on CIFAR regardless of the schedule. However, in the low-data regime, the "Hard-to-Easy" schedule consistently beat "Easy-to-Hard." We attribute this to an anti-memorization effect: heavy early augmentation prevents overfitting, while easing off later allows for refinement.
        </p>
        <p>
            In contrast, Color Robustness tests showed the exact opposite trend: "Easy-to-Hard" outperformed "Hard-to-Easy." This suggests that finishing with "easy" data boosts clean accuracy but causes the model to overfit to specific training colors, reducing robustness. We also found that Colorful Cutout did not improve color robustness as assumed, likely because local noise does not teach global color invariance.
        </p>
        <p>
            Ultimately, while "Hard-to-Easy" is powerful for data-scarce environments, and "Easy-to-Hard" favors robustness, a consistent static baseline often provides the best overall balance of stability and generalizability.
        </p>
    </div>
    <div class="margin-right-block"></div>
</div>

<div class="content-margin-container" id="citations">
    <div class="margin-left-block"></div>
    <div class="main-content-block">
        <div class='citation' id="references" style="height:auto"><br>
            <span style="font-size:16px">References:</span><br><br>

            <a id="ref_1"></a>[1] He, K., et al. "Deep residual learning for image recognition." CVPR 2016.<br><br>
            
            <a id="ref_2"></a>[2] DeVries, T., & Taylor, G. W. "Improved regularization of convolutional neural networks with cutout." arXiv 2017.<br><br>
            
            <a id="ref_3"></a>[3] Bengio, Y., et al. "Curriculum learning." ICML 2009.<br><br>

            <a id="ref_4"></a>[4] Frolov, S., et al. "ObjBlur: A Curriculum Learning Approach With Progressive Object-Level Blurring." arXiv 2024.<br><br>

            <a id="ref_5"></a>[5] Yang, S., et al. "EntAugment: Entropy-Driven Adaptive Data Augmentation Framework." arXiv 2024.<br><br>

            <a id="ref_6"></a>[6] Maltser, R. "Augmentation Curriculum Learning." Master's Thesis, Hebrew University of Jerusalem, 2025.<br><br>

            <a id="ref_7"></a>[7] Choi, J., & Kim, Y. "Colorful Cutout: Enhancing Image Data Augmentation with Curriculum Learning." ICLR Tiny Papers 2024.<br><br>
            <a id="ref_8"></a>[8] Krizhevsky, A., et al. "Learning multiple layers of features from tiny images." 2009.<br><br>
            <a id="ref_9"></a>[9] Wei, J., et al. "Few-Shot Text Classification with Triplet Networks, Data Augmentation, and Curriculum Learning." NAACL 2021.<br><br>
        </div>
    </div>
    <div class="margin-right-block"></div>
</div>

</body>
</html>