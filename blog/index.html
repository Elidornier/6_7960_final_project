<!DOCTYPE html>
<html>
<head>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
<link rel="shortcut icon" href="images/icon.ico">
<style type="text/css">
    /* 1. BASIC PAGE SETUP */
    body {
        background-color: #ffffff; /* Clean white background */
        color: #333333; /* Dark gray text is easier on eyes than pitch black */
        font-family: "Georgia", "Times New Roman", serif; /* Serif font for the main reading */
        font-size: 20px; /* Distill uses large, readable text */
        line-height: 1.6em; /* More breathing room between lines */
        margin: 0;
    }

    /* 2. LINKS (Blue) */
    a:link, a:visited {
        color: #2e6db2; 
        text-decoration: none;
        border-bottom: 1px solid #e0e0e0; /* Subtle underline */
    }
    a:hover {
        color: #1a4e85;
        border-bottom: 2px solid #1a4e85;
    }

    /* 3. LAYOUT GRID */
    .content-margin-container {
        display: flex;
        width: 100%;
        justify-content: center;
        align-items: flex-start; /* Aligns content to top */
        margin-bottom: 20px;
    }

    /* 4. MAIN COLUMN (Narrower for readability) */
    .main-content-block {
        width: 55%; 
        max-width: 720px; /* Optimal reading width */
        background-color: #fff;
        padding: 0px;
        /* We REMOVED the borders here */
        border: none; 
    }

    /* 5. MARGIN NOTES */
    .margin-left-block {
        width: 20%;
        max-width: 180px;
        margin-right: 30px;
        text-align: right;
        font-size: 14px;
        color: #6b6b6b;
        font-family: "HelveticaNeue-Light", "Helvetica Neue", sans-serif; /* Sidenotes stay sans-serif */
        line-height: 1.4em;
    }

    .margin-right-block {
        width: 20%;
        max-width: 220px; /* Slightly wider right margin */
        margin-left: 30px;
        text-align: left;
        font-size: 13px;
        color: #6b6b6b;
        font-family: "HelveticaNeue-Light", "Helvetica Neue", sans-serif;
        line-height: 1.4em;
    }

    /* 6. HEADERS */
    h1, h2, h3 {
        font-family: "HelveticaNeue-Light", "Helvetica Neue", Helvetica, Arial, sans-serif;
        color: #000;
        margin-top: 50px;
        margin-bottom: 15px;
        font-weight: 600;
        line-height: 1.2em;
    }
    h1 { font-size: 36px; letter-spacing: -0.5px; } /* Big section headers */
    h2 { font-size: 26px; border-bottom: 1px solid #eee; padding-bottom: 10px; }
    h3 { font-size: 20px; font-weight: 600; margin-top: 30px;}

    /* 7. IMAGES & CAPTIONS */
    img, .my-video {
        max-width: 100%;
        height: auto;
        display: block;
        margin: 20px auto;
        border-radius: 4px; 
        box-shadow: 0 4px 10px rgba(0,0,0,0.05); /* Subtle shadow for images */
    }

    /* 8. MATH & CODE */
    .mathjax-mobile, .mathml-non-mobile { display: none; }
    .show-mathml .mathml-non-mobile { display: block; }
    .show-mathjax .mathjax-mobile { display: block; }
    
    code {
        background-color: #f4f4f4;
        padding: 2px 5px;
        border-radius: 3px;
        font-family: "Courier New", Courier, monospace;
        font-size: 0.9em;
    }

    /* 9. CITATION BLOCK */
    div.citation {
        font-family: "HelveticaNeue-Light", "Helvetica Neue", sans-serif;
        font-size: 14px;
        background-color: #f7f7f7;
        padding: 20px;
        border-radius: 5px;
        border: 1px solid #eee;
    }

    /* 10. TITLE HEADER TABLE SPECIFIC */
    table.header {
        width: 100%;
        max-width: 100%;
    }

    /* 11. TOP NAVIGATION BAR */
    .nav-header {
        background-color: #23374d; /* Navy Blue */
        width: 100%;
        display: flex;
        justify-content: center;
        padding: 15px 0;
        font-family: "HelveticaNeue-Light", "Helvetica Neue", Helvetica, Arial, sans-serif;
        border-bottom: 1px solid rgba(0,0,0,0.1);
    }
    
    .nav-inner {
        width: 90%; 
        max-width: 1080px; /* Matches the width of the article content */
        display: flex;
        justify-content: space-between;
        align-items: center;
    }

    .nav-logo {
        font-weight: 600;
        font-size: 18px;
        color: white !important; /* Force white text */
        border-bottom: none !important; /* Remove underline */
        display: flex;
        align-items: center;
    }

    .nav-links a {
        color: rgba(255,255,255,0.7) !important; /* Slightly transparent white */
        margin-left: 25px;
        font-size: 12px;
        font-weight: 500;
        text-transform: uppercase; /* MAKES TEXT CAPS */
        letter-spacing: 0.5px;
        border-bottom: none !important;
        transition: color 0.2s;
    }

    .nav-links a:hover {
        color: #ffffff !important; /* Bright white on hover */
    }

</style>

<title>Trajectory of Augmentation Difficulty</title>
<meta property="og:title" content="Trajectory of Augmentation Difficulty" />
<meta charset="UTF-8">
</head>

<body>

<div class="nav-header">
    <div class="nav-inner">
        <a href="#" class="nav-logo">
            <span class="logo-icon"></span> 6.7960 Project
        </a>
        
        <div class="nav-links">
            <a href="#">About</a>
            <a href="#">Paper</a>
            <a href="#">Code</a>
            <a href="#">Team</a>
        </div>
    </div>
</div>

<div class="content-margin-container" style="margin-top: 60px; margin-bottom: 60px;">
    <div class="margin-left-block"></div>
    <div class="main-content-block">
        <h1 style="font-size: 50px; line-height: 1.1em; margin-bottom: 20px; font-family: 'Helvetica Neue', Helvetica, sans-serif;">
            Investigating the Trajectory<br>of Augmentation Difficulty
        </h1>
        
        <div style="font-family: 'Helvetica Neue', sans-serif; font-size: 18px; color: #555;">
            <p>
                <a href="#">Alice Xiao</a>, 
                <a href="#">Aimee Yu</a>, 
                <a href="#">Celinda Zhu</a>
            </p>
            <p style="font-size: 15px; color: #888;">
                Final Project for 6.7960, MIT &bull; Fall 2025
            </p>
        </div>
    </div>
    <div class="margin-right-block"></div>
</div>

<div class="content-margin-container" id="intro">
    <div class="margin-left-block">
        <div style="position:fixed; max-width:inherit; top:max(20%,120px)">
            <b style="font-size:16px">Outline</b><br><br>
            <a href="#intro">Introduction</a><br><br>
            <a href="#related_work">Related Work</a><br><br>
            <a href="#methodology">Methodology</a><br><br>
            <a href="#experiments">Experiments & Results</a><br><br>
            <a href="#discussion">Discussion</a><br><br>
        </div>
    </div>
    <div class="main-content-block">
        <h1>Introduction</h1>
        
        <h3>Motivation</h3>
        <p>
            Deep learning's remarkable success in computer vision can be attributed in large part to the capacity of powerful, over-parameterized models such as ResNet <a href="#ref_1">[1]</a> to generalize effectively beyond their training data. Consequently, Data Augmentation has emerged as a cornerstone technique to bridge the generalization gap, artificially expanding the training distribution through stochastic transformations like blurring, cropping, and occlusion.
        </p>
        <p>
            In our homework, we explored flipping and found it to be an interesting topic, deciding to dig deeper. However, standard data augmentation pipelines typically treat the training process as <strong>static</strong>. Augmentations are applied with random magnitudes drawn from a fixed distribution, regardless of the model's current learning state. This creates a fundamental misalignment between the data and the model:
        </p>
        <ul>
            <li>In <strong>early training stages</strong>, the model is trying to learn basic, low-level features like edges or shapes. Strong augmentations (such as massive cutout holes or high-frequency noise) might introduce excessive information loss, essentially "blinding" the model before it can see.</li>
            <li>In <strong>later training stages</strong>, the model has likely memorized the training data. Weak augmentations may fail to provide sufficient regularization, leading to overfitting.</li>
        </ul>
        <p>
            We hypothesize that the <strong>timing</strong> of difficulty is just as critical as the difficulty itself. Just as a human student would struggle if handed a complex calculus problem on day one, a neural network might struggle to converge if the signal-to-noise ratio is too low at initialization.
        </p>

        <h3>Curriculum Learning</h3>
        <p>
            Curriculum Learning, as proposed by Bengio et al. <a href="#ref_3">[3]</a>, formalizes this intuition. It suggests that models learn more effectively when samples are presented in a meaningful order of increasing difficulty ("Easy-to-Hard"). Recent adaptive frameworks like EntAugment <a href="#ref_5">[5]</a> and ObjBlur <a href="#ref_4">[4]</a> have successfully applied this principle to data augmentation, scaling augmentation intensity as the model matures to match its growing capacity.
        </p>

        <h3>Anti-Curriculum</h3>
        <p>
            Conversely, a counter-intuitive line of research suggests an "Anti-Curriculum" (Hard-to-Easy) approach. Theoretical work by Maltser <a href="#ref_6">[6]</a> indicates that exposing models to difficult, strongly augmented samples <strong>early on</strong> might force the learning of more robust, shape-invariant features. By front-loading the difficulty, the model may be prevented from learning "shortcuts" (like superficial texture bias) during its initial phase of high plasticity.
        </p>

        <h3>Our Contribution</h3>
        <p>
            In this work, we systematically investigate the <strong>trajectory of difficulty</strong> in data augmentation. We do not merely ask <em>if</em> curriculum learning helps; we ask <em>which trajectory</em> is optimal. We explore two distinct axes of difficulty:
        </p>
        <ol>
            <li><strong>Complexity-based:</strong> Using <strong>Colorful Cutout</strong> <a href="#ref_7">[7]</a> to vary the information entropy of the occluded region.</li>
            <li><strong>Occlusion-based:</strong> Using <strong>Dynamic Cutout Size</strong>, a method we implemented to vary the spatial extent of information loss.</li>
        </ol>
        <p>
            We compare three distinct training regimes:
        </p>
        <ul>
            <li><strong>Static Baseline:</strong> Random augmentation magnitude (Standard practice).</li>
            <li><strong>Curriculum (Easy &rarr; Hard):</strong> Gradually increasing complexity/occlusion.</li>
            <li><strong>Anti-Curriculum (Hard &rarr; Easy):</strong> Gradually decreasing complexity/occlusion.</li>
        </ul>
        <p>
            By training ResNet50 architectures on CIFAR-10 <a href="#ref_8">[8]</a> and CIFAR-100 under these varying dynamics, we aim to decouple the impact of augmentation <em>type</em> from augmentation <em>scheduling</em>.
        </p>
        <img src="./images/your_intro_diagram.png" width=512px/>
    </div>
    <div class="margin-right-block">
        <div style="margin-bottom: 20px;">
            <strong>Hypothesis:</strong><br>
            Does early exposure to "hard" augmentations (Anti-Curriculum) induce better robustness than the traditional "Easy-to-Hard" Curriculum?
        </div>
    </div>
</div>

<div class="content-margin-container" id="related_work">
    <div class="margin-left-block"></div>
    <div class="main-content-block">
        <h1>Related Work</h1>
        <p>
            Recent research has pivoted toward <strong>adaptive</strong> strategies that integrate curriculum learning: models learn faster and better when training examples are ordered from easy to hard <a href="#ref_3">[3]</a>.
        </p>
        <ul>
            <li><strong>ObjBlur <a href="#ref_4">[4]</a>:</strong> Introduces a curriculum for layout-to-image generation by progressively moving from strong blurring (low-frequency signals) to cleaner images (high-frequency details).</li>
            <li><strong>EntAugment <a href="#ref_5">[5]</a>:</strong> Proposes a tuning-free framework that adapts augmentation magnitude based on sample difficulty. It utilizes an entropy-based metric to assess model confidence, applying lighter augmentations to hard samples early in training and intensifying the magnitude as the model generalizes.</li>
        </ul>

        <h3>Magnitude-Based Scheduling</h3>
        <p>
            A key subset of Curriculum Data Augmentation focuses specifically on scheduling the <strong>intensity</strong> or <strong>magnitude</strong> of transformations. Wei et al. (2020) demonstrated that gradually increasing the magnitude of distortions (e.g., rotation angle, shear intensity) correlates with improved generalization <a href="#ref_9">[9]</a>.
        </p>
        <p>
            In the context of occlusion methods, this magnitude corresponds directly to the <strong>size</strong> of the erased region. While early occlusion methods like Cutout <a href="#ref_2">[2]</a> and Random Erasing utilized fixed or randomly sampled sizes, later works such as Hide-and-Seek highlighted the delicate balance required between occlusion and feature retention. Our <strong>Dynamic Cutout Size</strong> implementation serves as a direct instantiation of magnitude-based curriculum for occlusion: we explicitly schedule the bounding box dimension ($W \times H$) as a function of the training epoch.
        </p>

        <h3>The Directionality Debate</h3>
        <p>
            Finally, a critical, yet under-explored question is the <strong>trajectory</strong> of augmentation difficulty. While standard CL dictates an "Easy-to-Hard" schedule, recent work by Maltser on <strong>Augmentation Curriculum Learning (ACL)</strong> investigates alternative pacing, including "Anti-Curriculum" (Hard-to-Easy) strategies <a href="#ref_6">[6]</a>. Maltser's findings suggest that explicitly scoring and ordering augmentations can outperform random selection, but the optimal direction remains a subject of debate.
        </p>
        <p>
            In this project, we utilize <strong>Colorful Cutout</strong> <a href="#ref_7">[7]</a> to test these conflicting hypotheses. By progressively dividing the erasure box into smaller sub-regions, Colorful Cutout allows us to control the "complexity" of the noise. As the number of sub-regions increases, the sample becomes more "tangled" and difficult, naturally forming a difficulty gradient that we can invert or scale.
        </p>
    </div>
    <div class="margin-right-block">
        <strong>Key Concept:</strong><br>
        <em>Magnitude Scheduling</em>: Varying the intensity (size) of an augmentation over time.
    </div>
</div>

<div class="content-margin-container" id="methodology">
    <div class="margin-left-block"></div>
    <div class="main-content-block">
        <h1>Methodology</h1>
        <p>
            Our experimental framework is built on PyTorch, utilizing the <strong>CIFAR-10</strong> dataset <a href="#ref_8">[8]</a> and a <strong>ResNet50</strong> backbone <a href="#ref_1">[1]</a>. To isolate the effects of curriculum pacing, we maintain consistent hyperparameters across all runs (Batch Size=32, Learning Rate=5e-5), modifying only the augmentation pipeline.
        </p>

        <h3>Defining "Difficulty"</h3>
        <p>
            We define difficulty through the lens of information loss and signal complexity. We explore two specific augmentation modalities:
        </p>
        
        <h4>1. Colorful Cutout (Complexity-based)</h4>
        <p>
            Building on the work of Choi & Kim <a href="#ref_7">[7]</a>, this method occludes a portion of the image with a grid of random colors rather than black pixels.
        </p>
        <p>
            For a bounding box of size <i style="font-family: serif;">B</i>, we define the sub-region size <i style="font-family: serif;">S</i> as:
        </p>
        
        <center>
            <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
              <mi>S</mi>
              <mo>=</mo>
              <mfrac>
                <mi>B</mi>
                <msup>
                  <mn>2</mn>
                  <mtext>exponent</mtext>
                </msup>
              </mfrac>
            </math>
        </center>
        
        <p>
            where the <code>exponent</code> determines the granularity.
        </p>
        <ul>
            <li><strong>Easy (Low Exponent):</strong> Large <i style="font-family: serif;">S</i>, resulting in a few solid color blocks.</li>
            <li><strong>Hard (High Exponent):</strong> Small <i style="font-family: serif;">S</i>, resulting in high-frequency color noise.</li>
        </ul>
        
        <h4>2. Dynamic Cutout Size (Occlusion-based)</h4>
        <p>
            A standard cutout approach where the side length of the occluded region (<i style="font-family: serif;">L<sub>mask</sub></i>) varies dynamically between a minimum (<i style="font-family: serif;">L<sub>min</sub></i>) and maximum (<i style="font-family: serif;">L<sub>max</sub></i>).
        </p>
        <ul>
            <li><strong>Easy:</strong> Small mask (<i style="font-family: serif;">L<sub>min</sub></i>); minimal information loss.</li>
            <li><strong>Hard:</strong> Large mask (<i style="font-family: serif;">L<sub>max</sub></i>); significant semantic occlusion.</li>
        </ul>
        <h3>Pacing Functions</h3>
        <p>
            We implemented dynamic schedulers that adjust the augmentation parameters (<i style="font-family: serif;">N</i>, for Colorful Cutout, Size for Dynamic Cutout) as a linear function of the training epoch <i style="font-family: serif;">t</i>.
        </p>
        
        <h4>Increasing Difficulty (Curriculum)</h4>
        <p>
            For Colorful Cutout (`color_cutout_cur_incr`), we increase the exponent linearly, making the noise finer and more complex. For Dynamic Size (`cutout_dynamic_cur_incr`), we linearly increase the mask size:
        </p>
        
        <center>
            <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
              <msub>
                <mi>L</mi>
                <mtext>mask</mtext>
              </msub>
              <mo stretchy="false">(</mo>
              <mi>t</mi>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <msub>
                <mi>L</mi>
                <mtext>min</mtext>
              </msub>
              <mo>+</mo>
              <mfrac>
                <mi>t</mi>
                <msub>
                  <mi>T</mi>
                  <mtext>total</mtext>
                </msub>
              </mfrac>
              <mo>×</mo>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>L</mi>
                <mtext>max</mtext>
              </msub>
              <mo>-</mo>
              <msub>
                <mi>L</mi>
                <mtext>min</mtext>
              </msub>
              <mo stretchy="false">)</mo>
            </math>
        </center>

        <h4>Decreasing Difficulty (Anti-Curriculum)</h4>
        <p>
            For Colorful Cutout (`color_cutout_cur_decr`), we start with the highest exponent (max complexity) and decrease to 0. For Dynamic Size (`cutout_dynamic_cur_decr`), we start with the largest mask and shrink it, revealing more of the image as training converges:
        </p>
        
        <center>
            <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
              <msub>
                <mi>L</mi>
                <mtext>mask</mtext>
              </msub>
              <mo stretchy="false">(</mo>
              <mi>t</mi>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <msub>
                <mi>L</mi>
                <mtext>max</mtext>
              </msub>
              <mo>-</mo>
              <mfrac>
                <mi>t</mi>
                <msub>
                  <mi>T</mi>
                  <mtext>total</mtext>
                </msub>
              </mfrac>
              <mo>×</mo>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>L</mi>
                <mtext>max</mtext>
              </msub>
              <mo>-</mo>
              <msub>
                <mi>L</mi>
                <mtext>min</mtext>
              </msub>
              <mo stretchy="false">)</mo>
            </math>
        </center>
        
        <p>
           This allows us to test the trajectory of learning without changing the total amount of augmentation applied over the course of training.
        </p>
    </div>
    <div class="margin-right-block">
        <strong>Implementation:</strong><br>
        We utilize a modular argument parser to switch between <code>cur_incr</code> and <code>cur_decr</code> modes.
    </div>
</div>

<div class="content-margin-container" id="experiments">
    <div class="margin-left-block"></div>
    <div class="main-content-block">
        <h1>Experiments & Results</h1>
        <p>
            <em>(Results pending final training runs)</em>
        </p>
        
        <p>
            We compare the test accuracy of ResNet50 on CIFAR-10 across three conditions: Static Baseline, Increasing Difficulty, and Decreasing Difficulty.
        </p>
    </div>
    <div class="margin-right-block">
        Visualizations are critical. Ensure captions explain the main takeaway of the figure.
    </div>
</div>

<div class="content-margin-container" id="discussion">
    <div class="margin-left-block"></div>
    <div class="main-content-block">
        <h1>Discussion & Limitations</h1>
        
        <h3>Discussion</h3>
        <p>
            Our investigation aims to reveal whether the "Easy-to-Hard" intuition holds for data augmentation. If the Curriculum strategy dominates, it suggests that deep networks require a "warm-up" period to learn basic features before handling noise. However, if the Anti-Curriculum strategy proves effective, it would imply that early regularization is crucial for preventing the optimization trajectory from falling into sharp, non-generalizable local minima.
        </p>

        <h3>Limitations</h3>
        <p>
            <strong>Dataset Scale:</strong> Our experiments are limited to CIFAR-10. The dynamics of curriculum learning may differ significantly on higher-resolution datasets like ImageNet, where texture bias is more pronounced.
        </p>
        <p>
            <strong>Training Duration:</strong> Due to computational constraints, our experiments utilized shortened training cycles (5 epochs). While sufficient to observe convergence trends, long-term training dynamics (e.g., late-stage overfitting) might reveal different behaviors in a full production setting.
        </p>
        <p>
            <strong>Augmentation Scope:</strong> We focused exclusively on occlusion-based augmentations (Cutout variants). Geometric augmentations (Rotation, Warping) might respond differently to curriculum pacing.
        </p>
    </div>
    <div class="margin-right-block">
        Future work could explore <strong>oscillating schedules</strong> (Cyclical Learning Rates applied to augmentation).
    </div>
</div>

<div class="content-margin-container" id="citations">
    <div class="margin-left-block"></div>
    <div class="main-content-block">
        <div class='citation' id="references" style="height:auto"><br>
            <span style="font-size:16px">References:</span><br><br>

            <a id="ref_1"></a>[1] He, K., et al. "Deep residual learning for image recognition." CVPR 2016.<br><br>
            
            <a id="ref_2"></a>[2] DeVries, T., & Taylor, G. W. "Improved regularization of convolutional neural networks with cutout." arXiv 2017.<br><br>
            
            <a id="ref_3"></a>[3] Bengio, Y., et al. "Curriculum learning." ICML 2009.<br><br>

            <a id="ref_4"></a>[4] Frolov, S., et al. "ObjBlur: A Curriculum Learning Approach With Progressive Object-Level Blurring." arXiv 2024.<br><br>

            <a id="ref_5"></a>[5] Yang, S., et al. "EntAugment: Entropy-Driven Adaptive Data Augmentation Framework." arXiv 2024.<br><br>

            <a id="ref_6"></a>[6] Maltser, R. "Augmentation Curriculum Learning." Master's Thesis, Hebrew University of Jerusalem, 2025.<br><br>

            <a id="ref_7"></a>[7] Choi, J., & Kim, Y. "Colorful Cutout: Enhancing Image Data Augmentation with Curriculum Learning." ICLR Tiny Papers 2024.<br><br>
            
            <a id="ref_8"></a>[8] Krizhevsky, A., et al. "Learning multiple layers of features from tiny images." 2009.<br><br>

            <a id="ref_9"></a>[9] Wei, J., et al. "Few-Shot Text Classification with Triplet Networks, Data Augmentation, and Curriculum Learning." NAACL 2021.<br><br>

        </div>
    </div>
    <div class="margin-right-block"></div>
</div>

</body>
</html>